{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sample_set for each lab_batch in the sample table\n",
    "\n",
    "Run the cell below to parse through all samples in the `sample` table and generate a `sample_set` for each set of samples with a matching `lab_batch`. The created sample_sets will be named just like the `lab_batch`.\n",
    "\n",
    "This notebook can only _add_ samples to sample_sets (or create them), it cannot remove samples from existing sample_sets. This means that if the `lab_batch` of a sample is changed from `A` to `B`, it will be added to a sample_set `B` but not removed from `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firecloud.api as fapi\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "import pytz\n",
    "\n",
    "workspace_namespace = os.environ.get('WORKSPACE_NAMESPACE')\n",
    "workspace_name = os.environ.get('WORKSPACE_NAME')\n",
    "\n",
    "\n",
    "def group_samples_into_batches(table_name, available_tables):\n",
    "    \n",
    "    if os.path.exists('CreateSampleSets_data'):\n",
    "        os.system('rm -r CreateSampleSets_data')\n",
    "    os.system('mkdir -p CreateSampleSets_data')\n",
    "    \n",
    "    existing_sample_sets = dict()\n",
    "    \n",
    "    if f'{table_name}_set' in available_tables:\n",
    "        # Download current sample_set table\n",
    "        print(f'Downloading {table_name}_set table...')\n",
    "        sample_set_response = fapi.get_entities(workspace_namespace, workspace_name, f'{table_name}_set')\n",
    "        if not sample_set_response.ok:\n",
    "            raise RuntimeError(f'ERROR: {sample_set_response.text}')\n",
    "        sample_sets_dict = json.loads(sample_set_response.text)\n",
    "        existing_sample_sets = {s['name']:[e['entityName'] for e in s['attributes'][f'{table_name}s']['items']] for s in sample_sets_dict}\n",
    "\n",
    "    # Read samples from samples table\n",
    "    print(f'Reading {table_name} table...')\n",
    "    sample_response = fapi.get_entities(workspace_namespace, workspace_name, f'{table_name}')\n",
    "    if not sample_response.ok:\n",
    "        raise RuntimeError(f'ERROR: {sample_response.text}')\n",
    "\n",
    "    samples = json.loads(sample_response.text)\n",
    "    # Writing new sample_set_membership.tsv\n",
    "    added_sample_sets = set()\n",
    "    with open(f'CreateSampleSets_data/new_{table_name}_set_membership.tsv', 'w') as new_membership_file:\n",
    "        # Write header\n",
    "        new_membership_file.write(f'membership:{table_name}_set_id\\t{table_name}\\n')\n",
    "        for sample in samples:\n",
    "            if 'lab_batch' not in sample['attributes']:\n",
    "                continue\n",
    "            sample_name = sample['name']\n",
    "            lab_batch = sample['attributes']['lab_batch']\n",
    "            if lab_batch in existing_sample_sets and \\\n",
    "                    sample_name in existing_sample_sets[lab_batch]:\n",
    "                continue\n",
    "            new_membership_file.write(f'{lab_batch}\\t{sample_name}\\n')\n",
    "            added_sample_sets.add(lab_batch)\n",
    "\n",
    "    if len(added_sample_sets) == 0:\n",
    "        print(f'No new {table_name}_sets to be added.')\n",
    "    else:\n",
    "        if f'{table_name}_set' not in available_tables:\n",
    "            print(f'Creating new table {table_name}_set')\n",
    "            # Need to upload tsv to creat new table\n",
    "            with open(f'CreateSampleSets_data/new_{table_name}_set.tsv', 'w') as new_set_table:\n",
    "                new_set_table.write(f'entity:{table_name}_set_id\\n')\n",
    "                for lab_batch in added_sample_sets:\n",
    "                    new_set_table.write(f'{lab_batch}\\n')\n",
    "            upload_new_table_response = fapi.upload_entities_tsv(workspace_namespace, workspace_name, f'CreateSampleSets_data/new_{table_name}_set.tsv', \"flexible\")\n",
    "            if not upload_new_table_response.ok:\n",
    "                raise RuntimeError(f'ERROR: {upload_new_table_response.text}')\n",
    "        print(f'Uploading new {table_name}_set table... ')\n",
    "        upload_response = fapi.upload_entities_tsv(workspace_namespace, workspace_name, f'CreateSampleSets_data/new_{table_name}_set_membership.tsv', \"flexible\")\n",
    "        if not upload_response.ok:\n",
    "            raise RuntimeError(f'ERROR: {upload_response.text}')\n",
    "        # Add date and time created to sample_set\n",
    "        print(f'Adding date and time to newly created {table_name}_sets...')\n",
    "\n",
    "        now = str(datetime.now(pytz.timezone('US/Eastern')))\n",
    "        for i, lab_batch in enumerate(added_sample_sets):\n",
    "            update_response = fapi.update_entity(workspace_namespace, workspace_name, f'{table_name}_set', lab_batch, [{\"op\": \"AddUpdateAttribute\", \"attributeName\": \"time_sample_set_created\", \"addUpdateAttribute\": now }])\n",
    "            if not update_response.ok:\n",
    "                raise RuntimeError(f'ERROR: {update_response.text}')\n",
    "            print(f'    Completed {i+1}/{len(added_sample_sets)}')\n",
    "        # Uploading new sample_set table\n",
    "        print('SUCCESS')\n",
    "        print(f'Printing update {table_name}_set_membership.tsv:')\n",
    "        os.system(f'cat CreateSampleSets_data/new_{table_name}_set_membership.tsv')\n",
    "    os.system('rm -r CreateSampleSets_data')\n",
    "\n",
    "    \n",
    "print('Finding tables to group by lab_batch')\n",
    "entity_types_response = fapi.list_entity_types(workspace_namespace, workspace_name)\n",
    "if not entity_types_response.ok:\n",
    "    raise RuntimeError(f'ERROR: {entity_types_response.text}')\n",
    "    \n",
    "entity_types_dict = json.loads(entity_types_response.text)\n",
    "available_tables = entity_types_dict.keys()\n",
    "for table_name, description in entity_types_dict.items():\n",
    "    if all(x in description['attributeNames'] for x in ['is_control_sample', 'lab_batch']):\n",
    "        group_samples_into_batches(table_name, available_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}