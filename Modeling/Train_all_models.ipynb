{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4625b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import joblib\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier as EBM\n",
    "from interpret.perf import ROC\n",
    "from interpret import show\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, auc, roc_curve\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea673714",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b61b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(filepath, sep=\"\\t\", header=None, columns=None):\n",
    "    '''\n",
    "    this function loads the data from the given file path and returns a pandas dataframe\n",
    "    filepath: str, path to the file e.g. \"data/train.csv\"\n",
    "    sep: str, separator used in the file e.g. \",\", \"\\t\"\n",
    "    header: int, row number to use as the column names e.g. 0, None\n",
    "    columns: list, list of column names to use e.g. [\"col1\", \"col2\", \"col3\"]\n",
    "\n",
    "    '''\n",
    "    data_df = pd.read_csv(filepath, sep=sep, header=header, names=columns)\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_df, label_column, removed_labels, chosen_labels = {'TP': 0, 'FP': 1, 'FP_CA': 1}):\n",
    "    '''\n",
    "    this function preprocesses the data by removing the rows with the removed labels and mapping the labels to the chosen labels\n",
    "    data_df: pandas dataframe, dataframe to preprocess\n",
    "    label_column: str, name of the column containing the labels\n",
    "    removed_labels: list, list of labels to remove from the data\n",
    "    chosen_labels: dict, dictionary to map the labels to the chosen labels\n",
    "\n",
    "    '''\n",
    "    data_df = data_df[~data_df[label_column].isin(removed_labels)]\n",
    "    data_df = data_df.dropna(subset=[label_column])\n",
    "    data_df[label_column] = data_df[label_column].map(chosen_labels)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6114b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(data_df, label_column, size=1.0):\n",
    "    '''\n",
    "    this function balances the data by upsampling the minority class and downsampling the majority class\n",
    "    data_df: pandas dataframe, dataframe to balance\n",
    "    label_column: str, name of the column containing the labels\n",
    "    size: float, size of the minority class relative to the majority class\n",
    "    \n",
    "    '''\n",
    "    mx = data_df[label_column].value_counts().max() # get the maximum count of the labels\n",
    "    TP = data_df[data_df[label_column] == 0]\n",
    "    FP = data_df[data_df[label_column] == 1]\n",
    "\n",
    "    if len(TP)  == mx:\n",
    "        TP_downsampled = TP\n",
    "        FP_upsampled = resample(FP, replace=True, n_samples=int(len(TP)*size), random_state=27)\n",
    "    else:\n",
    "        FP_upsampled = FP\n",
    "        TP_downsampled = resample(TP, replace=True, n_samples=int(len(FP)*size), random_state=27)\n",
    "    \n",
    "        \n",
    "    balanced_data_df = pd.concat([TP_downsampled, FP_upsampled])\n",
    "    return balanced_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_df, label_column, drop_columns, scaler_flag=False, random_state=42):\n",
    "    '''\n",
    "    this function splits the data into training and testing sets\n",
    "    data_df: pandas dataframe, dataframe to split\n",
    "    label_column: str, name of the column containing the labels\n",
    "    drop_columns: list, list of columns to drop from the data\n",
    "    scaler_flag: bool, flag to scale the data\n",
    "    random_state: int, random state for reproducibility\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    X = data_df.drop([label_column, *drop_columns], axis=1)\n",
    "    y = data_df[label_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=random_state)\n",
    "    \n",
    "    if scaler_flag:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405d2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ebm(X_train, y_train, random_seed=42):\n",
    "    '''\n",
    "    this function trains the Explainable Boosting Machine model\n",
    "    X_train: numpy array, training features\n",
    "    y_train: numpy array, training labels\n",
    "    random_seed: int, random state for reproducibility\n",
    "    \n",
    "    '''\n",
    "    ebm = EBM(random_state=random_seed)\n",
    "    n_chunks = 100\n",
    "    X_train_chunks = np.array_split(X_train, n_chunks)\n",
    "    y_train_chunks = np.array_split(y_train, n_chunks)\n",
    "    for i in tqdm(range(n_chunks)):\n",
    "        ebm.fit(X_train_chunks[i], y_train_chunks[i])\n",
    "    \n",
    "    return ebm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ebm, X_test, y_test):\n",
    "    '''\n",
    "    this function evaluates the model using the test set\n",
    "    ebm: Explainable Boosting Machine model\n",
    "    X_test: numpy array, test features\n",
    "    y_test: numpy array, test labels\n",
    "        \n",
    "        '''\n",
    "    \n",
    "    y_pred = ebm.predict(X_test)\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    ebm_perf = ROC(ebm.predict_proba).explain_perf(X_test, y_test)\n",
    "    show(ebm_perf)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    return ebm_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_explanation(ebm):\n",
    "    global_explanation = ebm.explain_global()\n",
    "    show(global_explanation)\n",
    "    \n",
    "    return global_explanation\n",
    "\n",
    "def local_explanation(ebm, X_test, y_test , len = None):\n",
    "    if len:\n",
    "        local_explanation = ebm.explain_local(X_test[:len], y_test[:len])\n",
    "    else:\n",
    "        local_explanation = ebm.explain_local(X_test, y_test)\n",
    "    show(local_explanation)\n",
    "    return local_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selected_regions_positive(term_scores, all_regions, selected_regions, model_name):\n",
    "    \"\"\"\n",
    "    Plots the mean scores above 1 for selected regions using Plotly.\n",
    "    \n",
    "    Parameters:\n",
    "    term_scores (list of np.ndarray): List of term scores from the EBM model.\n",
    "    all_regions (list of str): List of all region names corresponding to the term scores.\n",
    "    selected_regions (list of str): List of region names to be selected for plotting.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the number of selected regions does not match the number of selected term scores.\n",
    "    \"\"\"\n",
    "    # Filter the term scores and regions\n",
    "    selected_term_scores = []\n",
    "    for region in selected_regions:\n",
    "        index = all_regions.index(region)\n",
    "        selected_term_scores.append(term_scores[index])\n",
    "\n",
    "    # Ensure the number of selected regions matches the number of selected term scores\n",
    "    if len(selected_term_scores) != len(selected_regions):\n",
    "        raise ValueError(\"The number of selected regions does not match the number of selected term scores.\")\n",
    "\n",
    "    # Initialize a dictionary to store the filtered scores\n",
    "    region_scores = {}\n",
    "\n",
    "    # Filter scores above 1 and compute the mean for each selected region\n",
    "    for i, scores in enumerate(selected_term_scores):\n",
    "        filtered_scores = scores[scores > 0]\n",
    "        if len(filtered_scores) > 0:\n",
    "            region_scores[selected_regions[i]] = filtered_scores.mean()  # Taking the mean value for simplicity\n",
    "\n",
    "    # Sort the regions by their mean scores above 1 from highest to lowest\n",
    "    sorted_region_scores = dict(sorted(region_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Create the bar plot using Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(sorted_region_scores.keys()),\n",
    "        y=list(sorted_region_scores.values()),\n",
    "        marker_color='#006db6'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'{model_name} Scores for Selected Regions',\n",
    "        xaxis_title='Region Name',\n",
    "        yaxis_title='Score',\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db329ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selected_regions(term_scores, all_regions, selected_regions, model_name):\n",
    "    \"\"\"\n",
    "    Plots the mean scores above 1 for selected regions using Plotly.\n",
    "    \n",
    "    Parameters:\n",
    "    term_scores (list of np.ndarray): List of term scores from the EBM model.\n",
    "    all_regions (list of str): List of all region names corresponding to the term scores.\n",
    "    selected_regions (list of str): List of region names to be selected for plotting.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If the number of selected regions does not match the number of selected term scores.\n",
    "    \"\"\"\n",
    "    # Filter the term scores and regions\n",
    "    selected_term_scores = []\n",
    "    for region in selected_regions:\n",
    "        index = all_regions.index(region)\n",
    "        selected_term_scores.append(term_scores[index])\n",
    "\n",
    "    # Ensure the number of selected regions matches the number of selected term scores\n",
    "    if len(selected_term_scores) != len(selected_regions):\n",
    "        raise ValueError(\"The number of selected regions does not match the number of selected term scores.\")\n",
    "\n",
    "    # Initialize a dictionary to store the filtered scores\n",
    "    region_scores = {}\n",
    "\n",
    "    # compute the mean for each selected region\n",
    "    for i, scores in enumerate(selected_term_scores):\n",
    "        region_scores[selected_regions[i]] = scores.max()\n",
    "        \n",
    "\n",
    "    # Sort the regions by their mean scores above 1 from highest to lowest\n",
    "    sorted_region_scores = dict(sorted(region_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    # Create the bar plot using Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(sorted_region_scores.keys()),\n",
    "        y=list(sorted_region_scores.values()),\n",
    "        marker_color='#006db6'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'{model_name} Scores for Selected Regions',\n",
    "        xaxis_title='Region Name',\n",
    "        yaxis_title='Score',\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_selected_regions_together(term_scores, all_regions, selected_regions, technologies):\n",
    "    \"\"\"\n",
    "    Plots the mean scores for selected regions using Plotly, with scores for different technologies side by side.\n",
    "\n",
    "    Parameters:\n",
    "    term_scores (list of np.ndarray): List of term scores from the EBM model.\n",
    "    all_regions (list of str): List of all region names corresponding to the term scores.\n",
    "    selected_regions (list of str): List of region names to be selected for plotting.\n",
    "    technologies (list of str): List of technology names corresponding to the term scores.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the number of selected regions does not match the number of selected term scores.\n",
    "    \"\"\"\n",
    "    # Filter the term scores and regions\n",
    "    selected_term_scores = []\n",
    "    for region in selected_regions:\n",
    "        if region in all_regions:\n",
    "            index = all_regions.index(region)\n",
    "            selected_term_scores.append([ts[index] for ts in term_scores])\n",
    "        else:\n",
    "            raise ValueError(f\"Region {region} not found in all_regions\")\n",
    "\n",
    "    # Ensure the number of selected regions matches the number of selected term scores\n",
    "    if len(selected_term_scores) != len(selected_regions):\n",
    "        raise ValueError(\"The number of selected regions does not match the number of selected term scores.\")\n",
    "\n",
    "    # Initialize a dictionary to store the scores\n",
    "    region_scores = {tech: {} for tech in technologies}\n",
    "\n",
    "    # Compute the max for each selected region for each technology\n",
    "    for tech, scores_list in zip(technologies, zip(*selected_term_scores)):\n",
    "        for i, scores in enumerate(scores_list):\n",
    "            if len(scores) > 0:\n",
    "                region_scores[tech][selected_regions[i]] = np.max(scores)\n",
    "\n",
    "    # Custom colors for each technology\n",
    "    colors = ['#006db6', '#ff6f61', '#2d7f5e']\n",
    "    colors = ['#000000', '#046bb3', '#8c8c8c']\n",
    "    # Create the bar plot using Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for tech, color in zip(technologies, colors):\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=selected_regions,\n",
    "            y=[region_scores[tech].get(region, 0) for region in selected_regions],\n",
    "            name=tech,\n",
    "            marker_color=color,\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Scores for Selected Regions by Technology',\n",
    "        xaxis_title='Region Name',\n",
    "        yaxis_title='Score',\n",
    "        barmode='group',\n",
    "        # font size for selected regions\n",
    "        xaxis_tickfont=dict(size=22),\n",
    "        # font size for legend\n",
    "        legend=dict(\n",
    "            title='Technology',\n",
    "            title_font_size=22,\n",
    "            font_size=24,\n",
    "        ),\n",
    "        yaxis_tickfont=dict(size=22),\n",
    "        font = dict(size=22),\n",
    "        width = 1920,\n",
    "        height = 720,\n",
    "\n",
    "        )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91debef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    joblib.dump(model, f\"{model_name}_model.pkl\")\n",
    "    print(f\"{model_name} model saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd492dc5",
   "metadata": {},
   "source": [
    "## Training Model on Various Technology VCFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afc076",
   "metadata": {},
   "source": [
    "\n",
    "This section extends the notebook to train models on VCFs from different sequencing technologies (Illumina, Ultima, PacBio) and rank their weakest regions of performance (FP and FN).\n",
    "\n",
    "### Steps:\n",
    "1. Load and preprocess data for each technology.\n",
    "2. Train models for each technology.\n",
    "3. Evaluate models to rank the weakest regions of performance.\n",
    "4. Compare the weakest regions of performance across technologies.\n",
    "5. Save the Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "illumina_data = load_data(\"./datasets/Illumina_dataset.txt\", sep=\"\\t\", columns=['chrom', 'pos', 'ref', 'alt', 'filter', 'lowmappabilityall', 'lowGC', 'HighGC', 'Homoploymers', 'SegDup', 'label'], header=0)\n",
    "ultima_data = load_data(\"./datasets/Ultima_dataset.txt\", sep=\"\\t\", columns=['chrom', 'pos', 'ref', 'alt', 'filter', 'lowmappabilityall', 'lowGC', 'HighGC', 'Homoploymers', 'SegDup', 'label'] , header=0)\n",
    "pacbio_data = load_data(\"./datasets/PacBio_dataset.txt\", sep=\"\\t\", columns=['chrom', 'pos', 'ref', 'alt', 'filter', 'lowmappabilityall', 'lowGC', 'HighGC', 'Homoploymers', 'SegDup', 'label'] , header=0)\n",
    "\n",
    "print(\"All datasets loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "illumina_data = preprocess_data(illumina_data, 'label', ['HARD', 'OUT', 'IGN'], {'TP': 0, 'FP': 1, 'FP_CA': 1})\n",
    "ultima_data = preprocess_data(ultima_data, 'label', ['HARD', 'OUT', 'IGN'], {'TP': 0, 'FP': 1, 'FP_CA': 1})\n",
    "pacbio_data = preprocess_data(pacbio_data, 'label', ['HARD', 'OUT', 'IGN'], {'TP': 0, 'FP': 1, 'FP_CA': 1})\n",
    "\n",
    "print(\"All datasets preprocessed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "illumina_data = balance_data(illumina_data, 'label')\n",
    "ultima_data = balance_data(ultima_data, 'label')\n",
    "pacbio_data = balance_data(pacbio_data, 'label')\n",
    "\n",
    "print(\"All datasets balanced successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(illumina_data['filter'].value_counts())\n",
    "print(ultima_data['filter'].value_counts())\n",
    "print(pacbio_data['filter'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df46aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "illumina_X_train, illumina_X_test, illumina_y_train, illumina_y_test = split_data(illumina_data, 'label', ['chrom', 'pos', 'ref', 'alt', 'filter'], random_state=90)\n",
    "ultima_X_train, ultima_X_test, ultima_y_train, ultima_y_test = split_data(ultima_data, 'label', ['chrom', 'pos', 'ref', 'alt', 'filter'], random_state=90)\n",
    "pacbio_X_train, pacbio_X_test, pacbio_y_train, pacbio_y_test = split_data(pacbio_data, 'label', ['chrom', 'pos', 'ref', 'alt', 'filter'],  random_state=90)\n",
    "\n",
    "print(\"All datasets split successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'illumina' : (illumina_X_train, illumina_y_train), 'ultima' : (ultima_X_train, ultima_y_train), 'pacbio' : (pacbio_X_train, pacbio_y_train)}\n",
    "\n",
    "# create the models to access them later\n",
    "illumina_ebm = None\n",
    "ultima_ebm = None\n",
    "pacbio_ebm = None\n",
    "\n",
    "for model, (X_train, y_train) in models.items():\n",
    "    print(f\"Training {model} model\")\n",
    "    if model == 'illumina':\n",
    "        illumina_ebm = train_ebm(X_train, y_train)\n",
    "    elif model == 'ultima':\n",
    "        ultima_ebm = train_ebm(X_train, y_train)\n",
    "    else:\n",
    "        pacbio_ebm = train_ebm(X_train, y_train)\n",
    "    print(f\"{model} model trained successfully\")\n",
    "\n",
    "print(\"All models trained successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d82e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models\n",
    "illumina_perf = evaluate_model(illumina_ebm, illumina_X_test, illumina_y_test)\n",
    "ultima_perf = evaluate_model(ultima_ebm, ultima_X_test, ultima_y_test)\n",
    "pacbio_perf = evaluate_model(pacbio_ebm, pacbio_X_test, pacbio_y_test)\n",
    "\n",
    "print(\"All models evaluated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8aa7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions = [\n",
    "    'lowmappabilityall', 'SegDup', 'Homopolymers', \n",
    "    'lowmappabilityall & Homopolymers', 'Homopolymers & SegDup', \n",
    "    'lowmappabilityall & SegDup', 'lowGC', \n",
    "    'lowGC & SegDup', 'lowGC & Homopolymers', 'HighGC'\n",
    "]\n",
    "\n",
    "all_ebms = {'Illumina': illumina_ebm, 'Ultima': ultima_ebm, 'PacBio': pacbio_ebm}\n",
    "selected_regions = ['lowmappabilityall', 'SegDup', 'Homopolymers', 'lowGC', 'HighGC']\n",
    "\n",
    "for model_name, ebm in all_ebms.items():\n",
    "    term_scores = ebm.term_scores_\n",
    "    plot_selected_regions(term_scores, all_regions, selected_regions, model_name)\n",
    "\n",
    "print(\"All selected regions plotted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8495faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_explanation(ultima_ebm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af72a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_scores = [illumina_ebm.term_scores_, ultima_ebm.term_scores_, pacbio_ebm.term_scores_]\n",
    "technologies = ['Illumina', 'Ultima', 'PacBio']\n",
    "all_regions = [\n",
    "    'lowmappabilityall', 'SegDup', 'Homopolymers', \n",
    "    'lowmappabilityall & Homopolymers', 'Homopolymers & SegDup', \n",
    "    'lowmappabilityall & SegDup', 'lowGC', \n",
    "    'lowGC & SegDup', 'lowGC & Homopolymers', 'HighGC'\n",
    "]\n",
    "selected_regions = ['lowmappabilityall', 'SegDup', 'Homopolymers', 'lowGC', 'HighGC']\n",
    "\n",
    "plot_selected_regions_together(term_scores, all_regions, selected_regions, technologies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(illumina_ebm, 'illumina')\n",
    "save_model(ultima_ebm, 'ultima')\n",
    "save_model(pacbio_ebm, 'pacbio')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
